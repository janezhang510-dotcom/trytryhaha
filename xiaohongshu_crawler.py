import requests
import json
import time
import random
from bs4 import BeautifulSoup

def get_headers():
    """ç”Ÿæˆéšæœºè¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨è¡Œä¸º"""
    user_agents = [
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 14_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.6 Safari/605.1.15",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 14_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"
    ]
    return {
        "User-Agent": random.choice(user_agents),
        "Accept": "application/json, text/plain, */*",
        "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
        "Referer": "https://www.xiaohongshu.com/",
        "Connection": "keep-alive",
        "Sec-Fetch-Dest": "empty",
        "Sec-Fetch-Mode": "cors",
        "Sec-Fetch-Site": "same-origin",
        "X-Requested-With": "XMLHttpRequest",
        "Content-Type": "application/json",
        "Cookie": "abRequestId=3a4b5c6d-7e8f-9g0h-1i2j-3k4l5m6n7o8p; xsecappid=xhs-pc-web; a1=198bcf8b560h4w8qfkxj57mnp00w8z33s4f00vxr375000315941; webId=9f8e7d6c5b4a3s2d1f0g; gsid=1234567890abcdefghijklmnopqrstuvwxyz; webBuild=4.8.0; xhsTrackerId=12345678-90ab-cdef-ghij-klmnopqrstuv; sec_poison_id=abcdefghijklmnopqrstuvwxyz123456"
    }

def crawl_xiaohongshu(keyword, max_pages=5):
    """
    æŠ“å–å°çº¢ä¹¦ç›¸å…³å†…å®¹
    :param keyword: æœç´¢å…³é”®è¯
    :param max_pages: æœ€å¤§æŠ“å–é¡µæ•°
    :return: æŠ“å–çš„å†…å®¹åˆ—è¡¨
    """
    items = []
    # å°è¯•ä½¿ç”¨ä¸åŒçš„APIç«¯ç‚¹
    base_urls = [
        "https://www.xiaohongshu.com/api/sns/v3/search/notes",
        "https://api.xiaohongshu.com/api/sns/v3/search/notes"
    ]
    
    for base_url in base_urls:
        print(f"å°è¯•ä½¿ç”¨APIç«¯ç‚¹: {base_url}")
        
        for page in range(1, max_pages + 1):
            params = {
                "keyword": keyword,
                "page": page,
                "page_size": 20,
                "sort": "popular"  # æŒ‰çƒ­åº¦æ’åº
            }
            
            try:
                headers = get_headers()
                # æ·»åŠ éšæœºå»¶è¿Ÿï¼Œé¿å…è¢«è¯†åˆ«ä¸ºçˆ¬è™«
                time.sleep(random.uniform(1, 3))
                
                response = requests.get(base_url, params=params, headers=headers, timeout=10)
                
                if response.status_code == 200:
                    data = response.json()
                    notes = data.get("data", {}).get("notes", [])
                    
                    if notes:
                        for note in notes:
                            item = {
                                "id": note.get("id"),
                                "title": note.get("title"),
                                "desc": note.get("desc"),
                                "likes": note.get("likes"),
                                "comments": note.get("comments"),
                                "collections": note.get("collections"),
                                "author": note.get("user", {}).get("nickname"),
                                "avatar": note.get("user", {}).get("avatar"),
                                "cover": note.get("image_list", [{}])[0].get("url", ""),
                                "url": f"https://www.xiaohongshu.com/explore/{note.get('id')}"
                            }
                            items.append(item)
                        
                        print(f"ç¬¬ {page} é¡µæŠ“å–å®Œæˆï¼Œè·å– {len(notes)} æ¡å†…å®¹")
                    else:
                        print(f"ç¬¬ {page} é¡µæ— å†…å®¹ï¼Œå¯èƒ½éœ€è¦ç™»å½•")
                else:
                    print(f"ç¬¬ {page} é¡µæŠ“å–å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                    # æ‰“å°å“åº”å†…å®¹ï¼Œä»¥ä¾¿åˆ†æ
                    if response.text:
                        print(f"å“åº”å†…å®¹: {response.text[:200]}...")
            
            except Exception as e:
                print(f"æŠ“å–ç¬¬ {page} é¡µæ—¶å‡ºé”™: {str(e)}")
                time.sleep(5)
        
        # å¦‚æœå·²ç»è·å–åˆ°å†…å®¹ï¼Œåœæ­¢å°è¯•å…¶ä»–APIç«¯ç‚¹
        if items:
            break
    
    return items

def calculate_hot_score(item):
    """
    è®¡ç®—çƒ­åº¦åˆ†æ•°
    :param item: å†…å®¹é¡¹
    :return: çƒ­åº¦åˆ†æ•°
    """
    likes = item.get("likes", 0)
    comments = item.get("comments", 0)
    collections = item.get("collections", 0)
    
    # æƒé‡åˆ†é…ï¼šæ”¶è— > ç‚¹èµ > è¯„è®º
    score = likes * 1 + comments * 2 + collections * 3
    return score

def get_top_items(items, top_n=10):
    """
    è·å–çƒ­åº¦æœ€é«˜çš„å‰Nä¸ªå†…å®¹
    :param items: å†…å®¹åˆ—è¡¨
    :param top_n: æ•°é‡
    :return: æ’åºåçš„å†…å®¹åˆ—è¡¨
    """
    items_with_score = []
    for item in items:
        item["hot_score"] = calculate_hot_score(item)
        items_with_score.append(item)
    
    # æŒ‰çƒ­åº¦åˆ†æ•°æ’åº
    sorted_items = sorted(items_with_score, key=lambda x: x["hot_score"], reverse=True)
    return sorted_items[:top_n]

def format_output(items):
    """
    æ ¼å¼åŒ–è¾“å‡ºç»“æœ
    :param items: å†…å®¹åˆ—è¡¨
    :return: æ ¼å¼åŒ–çš„å­—ç¬¦ä¸²
    """
    output = []
    for i, item in enumerate(items, 1):
        output.append(f"ç¬¬ {i} å:")
        output.append(f"æ ‡é¢˜: {item.get('title', 'æ— æ ‡é¢˜')}")
        output.append(f"æè¿°: {item.get('desc', 'æ— æè¿°')[:100]}...")
        output.append(f"çƒ­åº¦åˆ†æ•°: {item.get('hot_score')}")
        output.append(f"ç‚¹èµ: {item.get('likes', 0)}")
        output.append(f"è¯„è®º: {item.get('comments', 0)}")
        output.append(f"æ”¶è—: {item.get('collections', 0)}")
        output.append(f"ä½œè€…: {item.get('author', 'æœªçŸ¥')}")
        output.append(f"é“¾æ¥: {item.get('url')}")
        output.append("-" * 50)
    
    return "\n".join(output)

if __name__ == "__main__":
    print("å¼€å§‹æŠ“å–å°çº¢ä¹¦å¥³è£…çˆ†æ¬¾å†…å®¹...")
    
    # æŠ“å–å¥³è£…ç›¸å…³å†…å®¹
    items = crawl_xiaohongshu("å¥³è£…", max_pages=10)
    
    if items:
        print(f"\nå…±æŠ“å–åˆ° {len(items)} æ¡å†…å®¹")
        
        # è·å–çƒ­åº¦æœ€é«˜çš„å‰10ä¸ª
        top_items = get_top_items(items, top_n=10)
        
        print("\nğŸ”¥ å°çº¢ä¹¦å¥³è£…åå¤§çˆ†æ¬¾ ğŸ”¥")
        print(format_output(top_items))
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        with open("xiaohongshu_top10.json", "w", encoding="utf-8") as f:
            json.dump(top_items, f, ensure_ascii=False, indent=2)
        print("\nç»“æœå·²ä¿å­˜åˆ° xiaohongshu_top10.json æ–‡ä»¶")
    else:
        print("æœªæŠ“å–åˆ°ä»»ä½•å†…å®¹ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–è¯·æ±‚å‚æ•°")
